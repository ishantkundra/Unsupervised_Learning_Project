# ğŸš— Unsupervised Learning Project â€“ Car Clustering & Vehicle Classification

## ğŸ“Œ Project Overview

This project is divided into **two main parts**, each applying unsupervised and supervised learning techniques to solve real-world automotive problems. It involves clustering cars using K-Means and applying dimensionality reduction (PCA) followed by classification using Support Vector Machines (SVM).

---

## ğŸ§© Part A: Car Segmentation using K-Means Clustering

### ğŸš˜ Domain: Automobile (Fuel Efficiency)

### ğŸ“Š Datasets:
- `Car name.csv` â€“ Car model names
- `Car-Attributes.json` â€“ Attributes such as MPG, cylinders, horsepower, weight, displacement, etc.

### ğŸ§  Objective:
Understand and implement **K-Means clustering** to group similar cars based on performance and technical features.

### ğŸ› ï¸ Key Steps:
- Merged car name and attributes datasets
- Handled missing values (e.g., '?' in horsepower), and duplicates
- Conducted EDA:
  - Pairplots
  - Scatterplots with categorical color separation
  - 5-point summary
- Applied K-Means for `k=2` to `k=10`
- Visualized the elbow curve to find optimal `k`
- Labeled data with cluster assignments
- Predicted the cluster of new data points

### ğŸ“Œ Outcome:
Segmented cars into meaningful clusters based on multivariate attributes, enabling insights into fuel efficiency and design groupings.

---

## ğŸš™ Part B: Vehicle Classification using PCA & SVM

### ğŸ›» Domain: Automobile (Silhouette Recognition)

### ğŸ“Š Dataset:
- `vehicle.csv` â€“ Contains numeric features extracted from silhouettes of 4 vehicle types (bus, van, and two cars)

### ğŸ§  Objective:
Use **Principal Component Analysis (PCA)** to reduce feature dimensions and train an SVM model for vehicle type classification.

### ğŸ› ï¸ Key Steps:
- Cleaned and standardized the dataset
- Visualized class distribution and identified duplicates
- Trained a baseline **SVM classifier** and evaluated its performance
- Applied PCA:
  - Visualized cumulative explained variance
  - Selected components to retain â‰¥90% variance
- Re-trained SVM with PCA-transformed features
- Tuned hyperparameters to improve classification performance
- Compared results before and after dimensionality reduction

### ğŸ“Œ Outcome:
Improved classification performance through dimensionality reduction, showing that PCA can reduce complexity while preserving accuracy.

---

## âš™ï¸ Tools, Libraries & Skills Used

- **Programming:** Python
- **Data Analysis:** Pandas, NumPy
- **Visualization:** Seaborn, Matplotlib
- **Machine Learning:**
  - Clustering: K-Means
  - Dimensionality Reduction: Principal Component Analysis (PCA)
  - Classification: Support Vector Machines (SVM)
- **Other Skills:** EDA, Data Merging, Imputation, Feature Scaling, Elbow Method, Model Tuning

---

## ğŸ“ Repository Structure

<pre>

.
â”œâ”€â”€ code/
â”‚   â””â”€â”€ IK+-+Unsupervised+Learning.ipynb         # Main project notebook (Parts A & B)
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ Part1 - Car name.csv                     # Car name information
â”‚   â”œâ”€â”€ Part1 - Car-Attributes.json              # Car technical specifications
â”‚   â””â”€â”€ vehicle.csv                              # Vehicle silhouette classification data
â”‚
â”œâ”€â”€ Problem Statement/
â”‚   â””â”€â”€ USL_Problem Statement.pdf                # Project brief with tasks
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                                    # This file

</pre>

---

## ğŸ’¡ Key Learnings

- K-Means clustering and elbow method for unsupervised grouping  
- Visual EDA techniques for pattern discovery  
- Dimensionality reduction with PCA and its assumptions  
- Improved classifier performance through feature compression  
- Classification using SVM and model tuning best practices

---

## âœï¸ Author

**Ishant Kundra**  
ğŸ“§ [ishantkundra9@gmail.com]
ğŸ“ Masterâ€™s in Computer Science | AIML Track
